\section{Related Work}
\label{sec:related}



%Optimizing meshes for fit point cloud data has been approached through vertex additions and removals~\cite{Hoppe1994}, although this work assumes the point data are precise and dense.

This work detects and segments plant leaves in color images before fitting a $3$D mesh.  These detection and segmentation tasks can be challenging depending on the clutter, lighting, shadows, overlapping leaves, leaf textures etc., and there have been numerous research efforts in this area to address these challenges.

One class of approaches to leaf segmentation is through combining many low-level features.  Contour detection is well studied although only more recently have they been used for leaf shape and boundary segmentation.  Simple cues like color, texture and local brightness and its combination are extensively used in contour and image boundary detections~\cite{martin2004learning,valliammal2012leaf}. To enhance segmentation and boundary regions, active contours and several improved variants of it~\cite{mishra2011decoupled} are also found to be quite popular in computer vision community. LeafSnap~\cite{kumar2012leafsnap}, a popular mobile application tool that identifies leaf species from photographs of leafs,rely on the more simplistic method of segmenting leaf by estimating the foreground and background color distribution by using Expectation Maximization in the saturation value space of the HSV colorspace. Research has also gained particular attention on segmentation of overlapping leaves for leaf detection. Pape et al.~\cite{Pape2015} tackles the problem of segmenting overlapping leaves partly by thresholding on built 3D histograms cubes of Lab color space both for training and testing data, and the quality of segmentation depends on the homogeneity of training data.

Another class of segmentation methods uses prior models.  Manh et al.~\cite{Manh2001139} use deformable templates in weed leaf segmentation which consists of fitting a parametric models to leaf outlines in image, by minimizing energy term related to internal constraints of the model and salient features of the image, such as color of plant. In related work, Toshev et al.~\cite{toshev2012shape} use both geometric properties of object boundary edges and coherent saliency cues distinct from the background. The method overcomes clutter in realistic scenes by handling segmentation using object specific knowledge like similarity in shape (top-down approach) and region growing principles (bottom up approach) from cues like color texture and normalized perimeter of objects.  

A third approach includes Wei Ma et. al ~\cite{ma2008image} who proposes modeling leaves using voxels. It aims to deal with the highly cluttered background by extracting the more visible apex features (position, middle axis and neighborhood) of the leaves instead of intelligent segmentation, from the volumetric data recovered from the images.  Volumetric data provide pose and position of $3$D leaves, and the $3$D leaf shapes can be extracted from the optimized voxels.

For this paper we restrict ourselves to simplified conditions including non-overlapping leaves, low background clutter, and single plant types.  This is to focus on the task of accurate leaf boundary and surface estimation.  Hence our approach is not to constrain leaf boundaries with prior parametric shape models, but instead rely primarily on color cues for segmentation.




%Another goal for mesh fitting is to incrementally build full $3$D models of objects.  Zippered polygons~\cite{Turk1994} builds mesh models from range images and combines them discarding noisy points at the boundaries.  The method developed by Curless and Levoy~\cite{Curless:1996} populates a weighted voxel occupancy grid from the depth data and recovers the surface by triangulating an isosurface.  By raycasting this surface, new camera poses can be aligned and their depths maps contribute to and improve the voxel model.  Advantages of this method include that surface topology is automatically determined, additional data can be readily incorporated, holes can be filled when more data are collected and it incorporates directional uncertainty of range data into the models.  Recent approaches for environment modeling from RGB-D cameras such as Kinect Fusion~\cite{Izadi:2011,Newcombe:2011} build on this voxel modeling and accumulation.  For our application the sensor is fixed and there is no option for merging views from different perspectives.  Artifacts caused by discretization into voxels are significant particularly with high input noise, and the method is limited in incorporating surface smoothness priors. .......MOVE TO RELATED WORK


