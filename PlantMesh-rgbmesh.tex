\section{Color Image-Based Mesh Creation}
\label{sec:colormesh}

For simplicity, and since the focus of this work is on accurate individual leaf surface modeling, we assume leaves are not overlapping.  This allows us to rely primarily on the color image for leaf segmentation.  Initial segmentation is done using the K-means clustering on the ‘a’ and ‘b’ channels of the Lab color space.  We found that the ‘a’ and ‘b’ channels contain good discriminatory information on the leaf pigments~\cite{Pape2015}.  Using three clusters on these two channels in the k-means clustering was sufficient to obtain a rough mask of the leaf regions.  To refine the segmentation accuracy we then use simple linear iterative clustering (SLIC) superpixels~\cite{achanta2012slic} to split image into multiple homogenous regions.  In most cases the boundaries of these superpixels adhere closely to the leaf boundaries. To detect whether each superpixel belongs to the leaf pigments or not, the initial batch of superpixels are selected by computing the centroid of each of them and checking whether it falls within the initial mask developed by K-means cluster. Any non leaf superpixels that are chosen in the first selection are then filtered out by thresholding on the ratio of 'a' and 'b' channels of the Lab color space. The selected superpixels are then merged to create the segmented leaf segment.

We build line segment based on boundary pixels of the segmented plant/leaf boundaries. Since plant leaves are clumped together in a single structure, it is possible to get closed boundary on the entire segmented image of the plant. We then perform a polygonal approximation motivated by the merging technique~\cite{Leu1988231} process on the boundary by approximating straight lines with a maximum deviation of one pixels from pixels in the original boundary~\cite{KovesiMATLABCode}. The two end points of the approximated lines are saved as vertices that join an edge of the polygon.

Having obtained the polygonal approximation of the plant leaf boundaries, we then sample points with a uniform spacing of $\ell$ pixels on each side of the polygon. Uniform grid of points with a spacing of $r$ are also created in the entire image, and the grid points which fall within or on the mask built by integrating the leaf superpixels are only selected. Points falling within $\ell \leq r$ are removed from the set of selected grid points.  Both the selected grid points and the sampled points on the boundary are then used to create a Delaunay triangulation on the plant mask. Facets that lie outside the polygonal shape are removed by determining whether their midpoints of the line fall within the polygonal shape or not. The final meshes on a typical color plant image looks like that in Fig.~\ref{fig:beanimageprocess} ($d$).
