\begin{abstract}

Research into improving plant growth and yield relies on sensors to measure plant phonotypes, such as photosynthesis, in arrays of growth chambers.  The accuracy of these measured phenotypes can be improved if the $3$D surface area and orientations of leafs are known.  This paper addresses this need for automated $3$D plant leaf estimation by presenting a method for using an inexpensive time-of-flight sensor tightly integrated with a color camera to estimate $3$D leaf mesh models.  While these sensors provide dense depth, the noise in the depth is large compared to the surface features, making high-fidelity surface estimation challenging.  Our method seeks to maximize the resolution and accuracy of the estimated surface by combining features from multiple modalities of the sensor including dense depth, near infra-red reflectance, and color.  The result is an automated surface mesh that captures leaf boundary and shape information and filters out much of the noise.  Examples are shown on known shapes and real plant data.

\end{abstract}
